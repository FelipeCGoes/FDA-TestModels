{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\"basePreProcessedAllAbFinal_com_NaN.csv\")\n",
    "y_data = base[\"status\"]\n",
    "x_data = base.drop([\"status\"], axis=1)\n",
    "\n",
    "attrCount = x_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "folds = 10\n",
    "countFold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResults = {\"Model\": [], \"ACC-Balanced\": [], \"F1-Macro\": [], \"AUC\": [], \"MCC\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "classifier = RandomForestClassifier(random_state=random_state, criterion=\"gini\", max_features=13, n_estimators=1275, max_depth=32) #RF-PipeNone\n",
    "\n",
    "#classifier = RandomForestClassifier(random_state=random_state, criterion=\"log_loss\", max_features=7, n_estimators=1375, max_depth=62) #RF-Pipe-SCALER+PCA+SMOTE\n",
    "\n",
    "#classifier = RandomForestClassifier(random_state=random_state, criterion=\"entropy\", max_features=7, n_estimators=600, max_depth=27) #RF-Pipe-SCALER+SMOTE\n",
    "\n",
    "#classifier = RandomForestClassifier(random_state=random_state, criterion=\"gini\", max_features=7, n_estimators=900, max_depth=97) #RF-Pipe-IMPUTER+SCALER+PCA+SMOTE\n",
    "\n",
    "#classifier = RandomForestClassifier(random_state=random_state, criterion=\"gini\", max_features=17, n_estimators=775, max_depth=82) #RF-Pipe-IMPUTER+SCALER+SMOTE\n",
    "\n",
    "#classifier = RandomForestClassifier(random_state=random_state, criterion=\"log_loss\", max_features=13, n_estimators=1350, max_depth=47) #RF-Pipe-KNN_IMPUTER+SCALER+SMOTE\n",
    "\n",
    "#XGBoost\n",
    "\n",
    "#classifier = XGBClassifier(random_state=random_state, learning_rate=0.05, n_estimators=300, max_depth=8, subsample=0.8, colsample_bytree=0.5, gamma=0.4, min_child_weight=5) #XGB-PipeNone\n",
    "\n",
    "#classifier = XGBClassifier(random_state=random_state, learning_rate=0.025, n_estimators=450, max_depth=22, subsample=1.0, colsample_bytree=0.5, gamma=0.7000000000000001, min_child_weight=5) #XGB-Pipe-SCALER+PCA+SMOTE\n",
    "\n",
    "#classifier = XGBClassifier(random_state=random_state, learning_rate=0.05, n_estimators=425, max_depth=18, subsample=0.8, colsample_bytree=0.6000000000000001, gamma=0.30000000000000004, min_child_weight=3) #XGB-Pipe-SCALER+SMOTE\n",
    "\n",
    "#classifier = XGBClassifier(random_state=random_state, learning_rate=0.05, n_estimators=275, max_depth=18, subsample=0.8, colsample_bytree=0.7, gamma=0.5, min_child_weight=4) #XGB-Pipe-IMPUTER+SCALER+PCA+SMOTE\n",
    "\n",
    "#classifier = XGBClassifier(random_state=random_state, learning_rate=0.025, n_estimators=425, max_depth=8, subsample=0.9, colsample_bytree=0.5, gamma=1.3, min_child_weight=1 ) #XGB-Pipe-IMPUTER+SCALER+SMOTE\n",
    "\n",
    "#classifier = XGBClassifier(random_state=random_state, learning_rate=0.025, n_estimators=250, max_depth=10, subsample=0.9, colsample_bytree=0.5, gamma=1.0, min_child_weight=2) #XGB-Pipe-KNN_IMPUTER+SCALER+SMOTE\n",
    "\n",
    "#imputer = KNNImputer(n_neighbors=5)\n",
    "scaler = StandardScaler()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "countFold = 1\n",
    "\n",
    "results = {'ACC-Balanced':[], 'F1-Macro':[], 'AUC': [], 'MCC': []}\n",
    "\n",
    "#Treinamendo do modelo com k-fold corss validation e aplicação do pipeline\n",
    "for train_index, test_index in kf.split(base):\n",
    "    \n",
    "    x_train, x_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
    "    y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "\n",
    "    #Mean Imputation\n",
    "    #x_train = imputer.fit_transform(x_train) #Uncomment this for pipeline 2\n",
    "    #x_test = imputer.transform(x_test) #Uncomment this for pipeline 2\n",
    "\n",
    "    # Standardize the sets using the same scaler\n",
    "    #x_train = scaler.fit_transform(x_train)\n",
    "    #x_test = scaler.transform(x_test)\n",
    "\n",
    "    # Apply PCA to training data to retain 95% variance\n",
    "    #pca = PCA(n_components=0.95) #Comment this for pipeline 1_semPCA\n",
    "    #x_train = pca.fit_transform(x_train) #Comment this for pipeline 1_semPCA\n",
    "\n",
    "    # Apply the same PCA transformation to the test set\n",
    "    #x_test = pca.transform(x_test) #Comment this for pipeline 1_semPCA\n",
    "\n",
    "    # SMOTE augmentation on the PCA-reduced training set\n",
    "    #smote = SMOTE(k_neighbors=3, random_state=random_state)\n",
    "    #x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    x_train = pd.DataFrame(x_train)\n",
    "    x_test = pd.DataFrame(x_test)\n",
    "    \n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred_proba = classifier.predict_proba(x_test)[:, 1]\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int) #Threshold de 0.5 considerado\n",
    "\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    auc = roc_auc_score(y_test, y_pred_proba) #CORRIGIDO: y_pred -> y_pred_proba\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    results['ACC-Balanced'].append(balanced_acc)\n",
    "    results['F1-Macro'].append(f1_macro)\n",
    "    results['AUC'].append(auc)\n",
    "    results['MCC'].append(mcc)\n",
    "\n",
    "finalResults[\"Model\"].append(\"RF-Pipe-None\")\n",
    "finalResults[\"ACC-Balanced\"].append(np.average(results['ACC-Balanced']))\n",
    "finalResults[\"F1-Macro\"].append(np.average(results['F1-Macro']))\n",
    "finalResults[\"AUC\"].append(np.average(results['AUC']))\n",
    "finalResults[\"MCC\"].append(np.average(results['MCC']))\n",
    "\n",
    "print(finalResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDf = pd.DataFrame(finalResults)\n",
    "print(resultsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cuda\") if torch.cuda.is_available() else print(\"cpu\")\n",
    "global device \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = nn.Sequential(nn.Linear(attrCount, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "\n",
    "#Pipe None\n",
    "#Trial 13 finished with value: 0.8877320532336895 and parameters: {'num_layers': 2, 'n_units_layer_0': 512, 'n_units_layer_1': 32, 'activation': 'ReLU', 'use_batch_norm': False, 'use_dropout': True, 'optimizer': 'AdamW', 'lr': 0.00012295920205037024, 'weight_decay': 6.268225479552331e-05}. Best is trial 13 with value: 0.8877320532336895.\n",
    "\n",
    "#Pipe IMPUTER-SCALER-SMOTE\n",
    "#Trial 67 finished with value: 0.9471169493848363 and parameters: {'num_layers': 2, 'n_units_layer_0': 512, 'n_units_layer_1': 256, 'activation': 'ReLU', 'use_batch_norm': False, 'use_dropout': False, 'optimizer': 'AdamW', 'lr': 0.00037632176070769957, 'weight_decay': 1.873329227021332e-05}. Best is trial 67 with value: 0.9471169493848363. Best trial: 67. Best value: 0.947117\n",
    "\n",
    "# Modelo\n",
    "model = model.to(device)\n",
    "\n",
    "# Otimizador\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00037632176070769957, weight_decay=1.873329227021332e-05)\n",
    "\n",
    "#Loss\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "\n",
    "\n",
    "#imputer = KNNImputer(n_neighbors=5) #Botar fora da erro\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "countFold = 1\n",
    "results = {'ACC-Balanced':[], 'F1-Macro':[], 'AUC': [], 'MCC': []}\n",
    "\n",
    "#Treinamendo do modelo com k-fold corss validation e aplicação do pipeline\n",
    "for train_index, test_index in kf.split(base):\n",
    "    x_train, x_test = x_data.iloc[train_index], x_data.iloc[test_index]\n",
    "    y_train, y_test = y_data.iloc[train_index], y_data.iloc[test_index]\n",
    "\n",
    "    print(f\"Fold: {countFold}/{folds}\")\n",
    "    countFold += 1\n",
    "\n",
    "    #Mean Imputation\n",
    "    x_train = imputer.fit_transform(x_train) #Uncomment this for pipeline 2\n",
    "    x_test = imputer.transform(x_test) #Uncomment this for pipeline 2\n",
    "\n",
    "    # Standardize the sets using the same scaler\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # Apply PCA to training data to retain 95% variance\n",
    "    #pca = PCA(n_components=0.95) #Comment this for pipeline 1_semPCA\n",
    "    #x_train = pca.fit_transform(x_train) #Comment this for pipeline 1_semPCA\n",
    "\n",
    "    # Apply the same PCA transformation to the test set\n",
    "    #x_test = pca.transform(x_test) #Comment this for pipeline 1_semPCA\n",
    "\n",
    "    # SMOTE augmentation on the PCA-reduced training set\n",
    "    smote = SMOTE(k_neighbors=3, random_state=random_state)\n",
    "    x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "    x_train = pd.DataFrame(x_train)\n",
    "    x_test = pd.DataFrame(x_test)\n",
    "\n",
    "    x_train = torch.tensor(x_train.to_numpy(), dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "    # Treinamento\n",
    "    num_epochs = 500\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=32, shuffle=False) #pin_memory=True - Para GPU\n",
    "    val_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=32, shuffle=False) #pin_memory=True - Para GPU\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    #best_val_accuracy = 0.0\n",
    "    patience = 100\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Validação por epoca\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        y_preds, y_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch).squeeze()\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                y_preds.append(y_pred.cpu())\n",
    "                y_true.append(y_batch.cpu())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        y_preds = torch.cat(y_preds).round()\n",
    "        y_true = torch.cat(y_true)\n",
    "        val_accuracy = balanced_accuracy_score(y_true, y_preds)\n",
    "\n",
    "        # Early stopping check\n",
    "        #if val_loss < best_val_loss or val_accuracy > best_val_accuracy:\n",
    "            #best_val_loss = min(best_val_loss, val_loss)\n",
    "            #best_val_accuracy = max(best_val_accuracy, val_accuracy)\n",
    "            #counter = 0\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = min(best_val_loss, val_loss)\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "        #print(epoch)\n",
    "\n",
    "    # Avaliação final do fold\n",
    "    model.eval()\n",
    "    y_preds, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            y_preds.append(y_pred.cpu())\n",
    "            y_true.append(y_batch.cpu())\n",
    "\n",
    "    y_pred_proba = torch.cat(y_preds)\n",
    "    y_pred = (y_pred_proba >= 0.5).int() #Threshold de 0.5 considerado\n",
    "    y_test = torch.cat(y_true) #Mantido uso do y_true pois pode ser que os labels de teste não estejam na mesma posição das predições\n",
    "\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    auc = roc_auc_score(y_test, y_pred_proba) #CORRIGIDO: y_pred -> y_pred_proba\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    results['ACC-Balanced'].append(balanced_acc)\n",
    "    results['F1-Macro'].append(f1_macro)\n",
    "    results['AUC'].append(auc)\n",
    "    results['MCC'].append(mcc)\n",
    "\n",
    "print(np.mean(results[\"ACC-Balanced\"]))\n",
    "print(np.mean(results[\"F1-Macro\"]))\n",
    "print(np.mean(results[\"AUC\"]))\n",
    "print(np.mean(results[\"MCC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ACC-Balanced  F1-Macro       AUC       MCC\n",
      "0      0.688047  0.682988  0.688047  0.375928\n",
      "1      0.935781  0.935253  0.935781  0.870620\n",
      "2      0.943191  0.942690  0.943191  0.885431\n",
      "3      0.966542  0.966430  0.966542  0.932874\n",
      "4      0.961616  0.961282  0.961616  0.922680\n",
      "5      0.955020  0.953607  0.955020  0.909700\n",
      "6      0.984608  0.984491  0.984608  0.969035\n",
      "7      0.981785  0.981881  0.981785  0.963776\n",
      "8      0.994784  0.994784  0.994784  0.989569\n",
      "9      0.984272  0.984466  0.984272  0.968985\n"
     ]
    }
   ],
   "source": [
    "resultsDfMLP = pd.DataFrame(results)\n",
    "print(resultsDfMLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba) #CORRIGIDO: y_pred -> y_pred_proba\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Find the point corresponding to threshold = 0.5\n",
    "threshold_05_idx = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr, tpr, color='darkblue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1, label='Random Classifier')\n",
    "\n",
    "# Mark threshold = 0.5 point\n",
    "plt.scatter(fpr[threshold_05_idx], tpr[threshold_05_idx], color='red', s=100, edgecolors='black', label='Threshold = 0.5')\n",
    "\n",
    "# Labels and formatting\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.title('ROC Curve', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testes com holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasePreProcessedAllAbFinal.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "base = pd.read_csv(\"basePreProcessedAllAbFinal.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbase_reduced, holdout = train_test_split(base, test_size=0.1, random_state=random_state) \\n\\nx_test_holdout = holdout.drop([\"status\"], axis=1)\\ny_test_holdout = holdout[\"status\"]\\n\\nx_data = base_reduced.drop([\"status\"], axis=1)\\ny_data = base_reduced[\"status\"]\\n\\nattrCount = x_data.shape[1]\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_all = base.drop([\"status\"], axis=1)\n",
    "y_data_all = base[\"status\"]\n",
    "\n",
    "attrCount = x_data.shape[1]\n",
    "\n",
    "'''\n",
    "base_reduced, holdout = train_test_split(base, test_size=0.1, random_state=random_state) \n",
    "\n",
    "x_test_holdout = holdout.drop([\"status\"], axis=1)\n",
    "y_test_holdout = holdout[\"status\"]\n",
    "\n",
    "x_data = base_reduced.drop([\"status\"], axis=1)\n",
    "y_data = base_reduced[\"status\"]\n",
    "\n",
    "attrCount = x_data.shape[1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 116\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 112\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 108\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 119\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 103\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 171\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 122\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 117\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 151\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 112\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 108\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 108\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 101\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 110\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 146\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 103\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 111\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 108\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 213\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 103\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 112\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 115\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 103\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 128\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 108\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 103\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 144\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 110\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 107\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 108\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 127\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 142\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 191\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 173\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 153\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 114\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 107\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 108\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 138\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 111\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 230\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 102\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 136\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 103\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 114\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 114\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 109\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 100\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 107\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 100\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 161\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 105\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 110\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 109\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 107\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 137\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 119\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 121\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 103\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 103\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 133\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 117\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 107\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 101\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 105\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 103\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 100\n",
      "cpu\n",
      "Fold: 1/10\n",
      "Early stopping triggered at epoch 114\n",
      "Fold: 2/10\n",
      "Early stopping triggered at epoch 112\n",
      "Fold: 3/10\n",
      "Early stopping triggered at epoch 109\n",
      "Fold: 4/10\n",
      "Early stopping triggered at epoch 106\n",
      "Fold: 5/10\n",
      "Early stopping triggered at epoch 101\n",
      "Fold: 6/10\n",
      "Early stopping triggered at epoch 101\n",
      "Fold: 7/10\n",
      "Early stopping triggered at epoch 100\n",
      "Fold: 8/10\n",
      "Early stopping triggered at epoch 147\n",
      "Fold: 9/10\n",
      "Early stopping triggered at epoch 104\n",
      "Fold: 10/10\n",
      "Early stopping triggered at epoch 104\n",
      "0.9324260221382561\n",
      "0.9302083982133744\n",
      "0.9324260221382561\n",
      "0.866538253091449\n",
      "0.9252836907917636\n",
      "0.9242326753623697\n",
      "0.9252836907917636\n",
      "0.8537761096948471\n"
     ]
    }
   ],
   "source": [
    "kf2 = KFold(n_splits=folds, shuffle=True, random_state=random_state)   \n",
    "final_results_test = {'ACC-Balanced':[], 'F1-Macro':[], 'AUC': [], 'MCC': []}\n",
    "final_results_holdout = {'ACC-Balanced':[], 'F1-Macro':[], 'AUC': [], 'MCC': []}\n",
    "\n",
    "for base_reduced_index, holdout_index in kf.split(base):\n",
    "    x_reduced, x_holdout = x_data_all.iloc[base_reduced_index], x_data_all.iloc[holdout_index]\n",
    "    y_reduced, y_holdout = y_data_all.iloc[base_reduced_index], y_data_all.iloc[holdout_index]\n",
    "\n",
    "    x_test_holdout = x_holdout\n",
    "    y_test_holdout = y_holdout\n",
    "\n",
    "    x_data = x_reduced\n",
    "    y_data = y_reduced\n",
    "\n",
    "    attrCount = x_data.shape[1]\n",
    "\n",
    "    print(\"cuda\") if torch.cuda.is_available() else print(\"cpu\")\n",
    "    global device \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model = nn.Sequential(nn.Linear(attrCount, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 1),\n",
    "                    nn.Sigmoid()\n",
    "                    )\n",
    "\n",
    "\n",
    "    #Pipe None\n",
    "    #Trial 13 finished with value: 0.8877320532336895 and parameters: {'num_layers': 2, 'n_units_layer_0': 512, 'n_units_layer_1': 32, 'activation': 'ReLU', 'use_batch_norm': False, 'use_dropout': True, 'optimizer': 'AdamW', 'lr': 0.00012295920205037024, 'weight_decay': 6.268225479552331e-05}. Best is trial 13 with value: 0.8877320532336895.\n",
    "\n",
    "    #Pipe IMPUTER-SCALER-SMOTE\n",
    "    #Trial 67 finished with value: 0.9471169493848363 and parameters: {'num_layers': 2, 'n_units_layer_0': 512, 'n_units_layer_1': 256, 'activation': 'ReLU', 'use_batch_norm': False, 'use_dropout': False, 'optimizer': 'AdamW', 'lr': 0.00037632176070769957, 'weight_decay': 1.873329227021332e-05}. Best is trial 67 with value: 0.9471169493848363. Best trial: 67. Best value: 0.947117\n",
    "\n",
    "    # Modelo\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Otimizador\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.00037632176070769957, weight_decay=1.873329227021332e-05)\n",
    "\n",
    "    #Loss\n",
    "    loss_fn = nn.BCELoss().to(device)\n",
    "\n",
    "\n",
    "    #imputer = KNNImputer(n_neighbors=5) #Botar fora da erro\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    scaler = StandardScaler()\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    countFold = 1\n",
    "    results = {'ACC-Balanced':[], 'F1-Macro':[], 'AUC': [], 'MCC': []}\n",
    "    results_holdout = {'ACC-Balanced':[], 'F1-Macro':[], 'AUC': [], 'MCC': []}\n",
    "\n",
    "    #Treinamendo do modelo com k-fold corss validation e aplicação do pipeline\n",
    "    for train_index, test_index in kf.split(x_reduced, y_reduced):\n",
    "        x_train, x_test = x_reduced.iloc[train_index], x_reduced.iloc[test_index]\n",
    "        y_train, y_test = y_reduced.iloc[train_index], y_reduced.iloc[test_index]\n",
    "\n",
    "        print(f\"Fold: {countFold}/{folds}\")\n",
    "        countFold += 1\n",
    "\n",
    "        #Mean Imputation\n",
    "        x_train = imputer.fit_transform(x_train) #Uncomment this for pipeline 2\n",
    "        x_test = imputer.transform(x_test) #Uncomment this for pipeline 2\n",
    "        if countFold == 1:\n",
    "            x_test_holdout = imputer.transform(x_test_holdout)\n",
    "        \n",
    "        # Standardize the sets using the same scaler\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        if countFold == 1:\n",
    "            x_test_holdout = scaler.transform(x_test_holdout)\n",
    "\n",
    "        # Apply PCA to training data to retain 95% variance\n",
    "        #pca = PCA(n_components=0.95) #Comment this for pipeline 1_semPCA\n",
    "        #x_train = pca.fit_transform(x_train) #Comment this for pipeline 1_semPCA\n",
    "\n",
    "        # Apply the same PCA transformation to the test set\n",
    "        #x_test = pca.transform(x_test) #Comment this for pipeline 1_semPCA\n",
    "\n",
    "        # SMOTE augmentation on the PCA-reduced training set\n",
    "        smote = SMOTE(k_neighbors=3, random_state=random_state)\n",
    "        x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "        x_train = pd.DataFrame(x_train)\n",
    "        x_test = pd.DataFrame(x_test)\n",
    "        x_test_holdout = pd.DataFrame(x_test_holdout)\n",
    "\n",
    "        x_train = torch.tensor(x_train.to_numpy(), dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "        x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32)\n",
    "        y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "        if countFold == 1:\n",
    "            x_test_holdout = torch.tensor(x_test_holdout.to_numpy(), dtype=torch.float32)\n",
    "            y_test_holdout = torch.tensor(y_test_holdout.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "        # Treinamento\n",
    "        num_epochs = 500\n",
    "        model.to(device)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=32, shuffle=False) #pin_memory=True - Para GPU\n",
    "        val_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=32, shuffle=False) #pin_memory=True - Para GPU\n",
    "        if countFold == 1:\n",
    "            holdout_loader = DataLoader(TensorDataset(x_test_holdout, y_test_holdout), batch_size=32, shuffle=False) #pin_memory=True - Para GPU\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        #best_val_accuracy = 0.0\n",
    "        patience = 100\n",
    "        counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(X_batch).squeeze()\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            # Validação por epoca\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            y_preds, y_true = [], []\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    y_pred = model(X_batch).squeeze()\n",
    "                    loss = loss_fn(y_pred, y_batch)\n",
    "                    val_loss += loss.item()\n",
    "                    y_preds.append(y_pred.cpu())\n",
    "                    y_true.append(y_batch.cpu())\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            y_preds = torch.cat(y_preds).round()\n",
    "            y_true = torch.cat(y_true)\n",
    "            val_accuracy = balanced_accuracy_score(y_true, y_preds)\n",
    "\n",
    "            # Early stopping check\n",
    "            #if val_loss < best_val_loss or val_accuracy > best_val_accuracy:\n",
    "                #best_val_loss = min(best_val_loss, val_loss)\n",
    "                #best_val_accuracy = max(best_val_accuracy, val_accuracy)\n",
    "                #counter = 0\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = min(best_val_loss, val_loss)\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                    break\n",
    "            #print(epoch)\n",
    "\n",
    "        # Avaliação final do fold\n",
    "        model.eval()\n",
    "        y_preds, y_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch).squeeze()\n",
    "                y_preds.append(y_pred.cpu())\n",
    "                y_true.append(y_batch.cpu())\n",
    "\n",
    "        y_pred_proba = torch.cat(y_preds)\n",
    "        y_pred = (y_pred_proba >= 0.5).int() #Threshold de 0.5 considerado\n",
    "        y_test = torch.cat(y_true) #Mantido uso do y_true pois pode ser que os labels de teste não estejam na mesma posição das predições\n",
    "\n",
    "        balanced_acc = balanced_accuracy_score(y_test, y_pred) #Se quisermos maximizar a acurácia balanceada\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro') #Se quisermos maximizar o F1 macro\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred) #Se quisermos maximizar o MCC\n",
    "\n",
    "        results['ACC-Balanced'].append(balanced_acc)\n",
    "        results['F1-Macro'].append(f1_macro)\n",
    "        results['AUC'].append(auc)\n",
    "        results['MCC'].append(mcc)\n",
    "\n",
    "        # Avaliação final do fold com holdout\n",
    "        model.eval()\n",
    "        y_preds, y_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in holdout_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch).squeeze()\n",
    "                y_preds.append(y_pred.cpu())\n",
    "                y_true.append(y_batch.cpu())\n",
    "\n",
    "        y_pred_proba = torch.cat(y_preds)\n",
    "        y_pred = (y_pred_proba >= 0.5).int() #Threshold de 0.5 considerado\n",
    "        y_test = torch.cat(y_true) #Mantido uso do y_true pois pode ser que os labels de teste não estejam na mesma posição das predições\n",
    "\n",
    "        balanced_acc = balanced_accuracy_score(y_test, y_pred) #Se quisermos maximizar a acurácia balanceada\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro') #Se quisermos maximizar o F1 macro\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred) #Se quisermos maximizar o MCC\n",
    "\n",
    "        results_holdout['ACC-Balanced'].append(balanced_acc)\n",
    "        results_holdout['F1-Macro'].append(f1_macro)\n",
    "        results_holdout['AUC'].append(auc)\n",
    "        results_holdout['MCC'].append(mcc)\n",
    "\n",
    "    final_results_test['ACC-Balanced'].append(np.mean(results[\"ACC-Balanced\"]))\n",
    "    final_results_test['F1-Macro'].append(np.mean(results[\"F1-Macro\"]))\n",
    "    final_results_test['AUC'].append(np.mean(results[\"AUC\"]))\n",
    "    final_results_test['MCC'].append(np.mean(results[\"MCC\"]))\n",
    "\n",
    "    final_results_holdout['ACC-Balanced'].append(np.mean(results_holdout[\"ACC-Balanced\"]))\n",
    "    final_results_holdout['F1-Macro'].append(np.mean(results_holdout[\"F1-Macro\"]))\n",
    "    final_results_holdout['AUC'].append(np.mean(results_holdout[\"AUC\"]))\n",
    "    final_results_holdout['MCC'].append(np.mean(results_holdout[\"MCC\"]))\n",
    "\n",
    "print(np.mean(final_results_test[\"ACC-Balanced\"]))\n",
    "print(np.mean(final_results_test[\"F1-Macro\"]))\n",
    "print(np.mean(final_results_test[\"AUC\"]))\n",
    "print(np.mean(final_results_test[\"MCC\"]))\n",
    "\n",
    "print(np.mean(final_results_holdout[\"ACC-Balanced\"]))\n",
    "print(np.mean(final_results_holdout[\"F1-Macro\"]))\n",
    "print(np.mean(final_results_holdout[\"AUC\"]))\n",
    "print(np.mean(final_results_holdout[\"MCC\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ACC-Balanced  F1-Macro       AUC       MCC\n",
      "0      0.904158  0.898154  0.904158  0.816054\n",
      "1      0.941055  0.939996  0.941055  0.882885\n",
      "2      0.920377  0.918007  0.920377  0.844110\n",
      "3      0.932255  0.929812  0.932255  0.866106\n",
      "4      0.939748  0.938980  0.939748  0.879333\n",
      "5      0.929756  0.924411  0.929756  0.863294\n",
      "6      0.946311  0.945803  0.946311  0.892049\n",
      "7      0.939702  0.938850  0.939702  0.878313\n",
      "8      0.942451  0.941105  0.942451  0.885126\n",
      "9      0.928446  0.926965  0.928446  0.858112\n",
      "   ACC-Balanced  F1-Macro       AUC       MCC\n",
      "0      0.894046  0.889901  0.894046  0.797220\n",
      "1      0.947808  0.947570  0.947808  0.895681\n",
      "2      0.901687  0.901342  0.901687  0.810459\n",
      "3      0.916386  0.915634  0.916386  0.835846\n",
      "4      0.942204  0.942299  0.942204  0.885292\n",
      "5      0.927884  0.923464  0.927884  0.863646\n",
      "6      0.934368  0.935638  0.934368  0.871974\n",
      "7      0.941685  0.941817  0.941685  0.884081\n",
      "8      0.935569  0.935125  0.935569  0.870911\n",
      "9      0.911199  0.909537  0.911199  0.822651\n"
     ]
    }
   ],
   "source": [
    "final_resultsDf = pd.DataFrame(final_results_test)\n",
    "print(final_resultsDf)\n",
    "\n",
    "final_resultsDfHoldout = pd.DataFrame(final_results_holdout)\n",
    "print(final_resultsDfHoldout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9324260221382561\n",
    "0.9302083982133744\n",
    "0.9324260221382561\n",
    "0.866538253091449\n",
    "0.9252836907917636\n",
    "0.9242326753623697\n",
    "0.9252836907917636\n",
    "0.8537761096948471\n",
    "\n",
    "Fold   ACC-Balanced  F1-Macro       AUC       MCC\n",
    "0      0.904158  0.898154  0.904158  0.816054\n",
    "1      0.941055  0.939996  0.941055  0.882885\n",
    "2      0.920377  0.918007  0.920377  0.844110\n",
    "3      0.932255  0.929812  0.932255  0.866106\n",
    "4      0.939748  0.938980  0.939748  0.879333\n",
    "5      0.929756  0.924411  0.929756  0.863294\n",
    "6      0.946311  0.945803  0.946311  0.892049\n",
    "7      0.939702  0.938850  0.939702  0.878313\n",
    "8      0.942451  0.941105  0.942451  0.885126\n",
    "9      0.928446  0.926965  0.928446  0.858112\n",
    "Fold   ACC-Balanced  F1-Macro       AUC       MCC\n",
    "0      0.894046  0.889901  0.894046  0.797220\n",
    "1      0.947808  0.947570  0.947808  0.895681\n",
    "2      0.901687  0.901342  0.901687  0.810459\n",
    "3      0.916386  0.915634  0.916386  0.835846\n",
    "4      0.942204  0.942299  0.942204  0.885292\n",
    "5      0.927884  0.923464  0.927884  0.863646\n",
    "6      0.934368  0.935638  0.934368  0.871974\n",
    "7      0.941685  0.941817  0.941685  0.884081\n",
    "8      0.935569  0.935125  0.935569  0.870911\n",
    "9      0.911199  0.909537  0.911199  0.822651"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
